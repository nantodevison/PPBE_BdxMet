get_ipython().run_line_magic("load_ext", " autoreload")
get_ipython().run_line_magic("autoreload", " 2")


import sys
sys.path.append(r'C:\Users\martin.schoreisz\git\otv\otv\Transfert_Donnees')
sys.path.append(r'C:\Users\martin.schoreisz\git\Outils\Outils\src')
sys.path.append(r'C:\Users\martin.schoreisz\Box\Cerema\3E-Prod_Env_Risq\E6-Nuisances\E61-Acoustique\60-Etudes_Locales\2022-BruitRessentiBdxMet\4-Travaux_en_cours\donnees_produites\Codes\src\Carac_situ_acoustiq')
sys.path.append(r'C:\Users\martin.schoreisz\Box\Cerema\3E-Prod_Env_Risq\E6-Nuisances\E61-Acoustique\60-Etudes_Locales\2022-BruitRessentiBdxMet\4-Travaux_en_cours\donnees_produites\Codes\src')

import os, re
import pandas as pd
import numpy as np
import altair as alt
from math import pi, log, cos, sqrt, radians, degrees
from datetime import timedelta, datetime, time
from IPython.display import Image
from Import_stockage_donnees.Import_export_bdd import FichierMesureBruitCsv, FichierCsvEnquete, ResultatsEnquete, FichiersMeteo
from Import_stockage_donnees.Params import (bdd, attributMesureTrafic, listFichiers6Min, fichierHoraireS43, dicoSiteLibCanal, dossierTrafic,
                                            fichierHoraireS44S45, dicoLibCanalVoie, dicoLibCanalSens, listNatureMesure)
from Connexions import Connexion_Transfert as ct
from Bruit.Niveaux import niveau2Pression, pression2Niveau, moyenneQuadratiquePression
from Bruit.Meteo import *
from statistics import mean, harmonic_mean
from Import_trafics import Comptage_Dira

pd.set_option('display.max_rows', 100)
pd.set_option('display.max_columns', 50)
pd.set_option('display.max_colwidth', 100)
# alt.data_transformers.disable_max_rows()
# alt.data_transformers.enable('json')


# exemple de lecture 
test = FichierMesureBruitCsv(r'C:\Users\martin.schoreisz\Documents\temp\BruitRessenti\mesures\CSV\sono1_10RuePierreRonsard\sono1_02-04-2022.csv')
# test.dfNiveauSpectre.head(10)


# transfert vers Bdd par dossier
dossierSrc = r'C:\Users\martin.schoreisz\Documents\temp\BruitRessenti\mesures\CSV\sono4_26RueFrancoisVillon'
transfertFichierMesure2Bdd(dossierSrc)


ressenti = FichierCsvEnquete(r'C:\Users\martin.schoreisz\Box\Cerema\3E-Prod_Env_Risq\E6-Nuisances\E61-Acoustique\60-Etudes_Locales\2022-BruitRessentiBdxMet\4-Travaux_en_cours\Enquete_LimeSurvey\resultats_LimeSurvey_Bruts\resultats_complets_enquete_avec_papier.csv')
# cf les attributs pour consulter les données si besoin


fichierMeteo = FichiersMeteo(r'C:\Users\martin.schoreisz\Box\Cerema\3E-Prod_Env_Risq\E6-Nuisances\E61-Acoustique\60-Etudes_Locales\2022-BruitRessentiBdxMet\4-Travaux_en_cours\mesures\station_meteo\datas',
                             ['Mesures_Ech24_21-03-2022_04-04-2022.csv', 'Mesures_Ech24_04-04-2022_19-04-2022.csv'])


# preparation des données de comparaison des girouettes
dfDirVentComp = fichierMeteo.analyseDirVents(fichierMeteo.dfBrutes)
# si besoin : fichierMeteo.graphDiffDirVent(dfDirVentComp, fichier_de_sauvegarde)
# visu des résultats
Image('images/ecart_dirVent_HautBas.png', width=600, height=600)


dossier = r'C:\Users\martin.schoreisz\Box\Cerema\3E-Prod_Env_Risq\E6-Nuisances\E61-Acoustique\60-Etudes_Locales\2022-BruitRessentiBdxMet\4-Travaux_en_cours\donnees_sources\MeteoFrance'
fichiersMesures = ['synop.202203.csv',  'synop.202204.csv']
dfMeteoFranceAll = pd.concat([pd.read_csv(os.path.join(dossier, f),
                                          sep=';',
                                          na_values='mq',
                                          usecols=listeColonnesMeteoFrance,
                                          parse_dates=[1]) for f in fichiersMesures]).rename(columns=dicoColonneMeteoFrance)
dfMeteoFranceBx = dfMeteoFranceAll.loc[dfMeteoFranceAll.station == numStationMerignac].copy()


with ct.ConnexionBdd(bdd) as c:
    dfMeteoFranceBx.to_sql('meteo_france', c.sqlAlchemyConn, schema='mesures_physiques')


# ouverture et filtre des données
df6Min = pd.concat([pd.read_excel(f) for f in listFichiers6Min])
df6MinFiltre = df6Min.loc[df6Min['Lib Canal'].isin(dicoLibCanalVoie.keys()) & (df6Min['nature de mesure'].isin(listNatureMesure))] .copy()


# traitement des données 6 minutes
df6MinFiltre['date_heure'] = df6MinFiltre.apply(lambda x: pd.to_datetime(f'{x.jour} {x.sequence}') + pd.to_timedelta('1 s'), axis=1)
df6MinFiltre.loc[df6MinFiltre['nature de mesure'] == 'Débit', 'indicateur'] = 'TV'
df6MinFiltre.loc[df6MinFiltre['nature de mesure'] == 'Vitesse', 'indicateur'] = 'Vmoy'
df6MinFiltre['id_instru_site'] = df6MinFiltre['Lib Canal'].apply(lambda x: [k for k, v in dicoSiteLibCanal.items() if x in v][0])
df6MinFiltre['voie'] = df6MinFiltre['Lib Canal'].apply(lambda x: dicoLibCanalVoie[x])
df6MinFiltre['sens'] = df6MinFiltre['Lib Canal'].apply(lambda x: dicoLibCanalSens[x])
df6MinFiltre['periode_agreg'] = '6 min'
df6MinFiltre.rename(columns={'mesure': 'valeur'}, inplace = True)
df6MinFinal = df6MinFiltre.loc[df6MinFiltre.valeur.notna()].drop([c for c in df6MinFiltre.columns if c not in attributMesureTrafic], axis=1)


# traiatements des données horaires
dira = Comptage_Dira('toto', dossierTrafic, 'tutu', 2022, 'compteur')
dfHoraireBrute = pd.concat([dira.miseEnFormeFichier(fichierHoraireS43, nbJoursValideMin=1, FlagHorsOTV=True, nbHeure0Max=24).assign(id_instru_site=7),
                            dira.miseEnFormeFichier(fichierHoraireS44S45, nbJoursValideMin=1, FlagHorsOTV=True, nbHeure0Max=24).assign(id_instru_site=8)])
dfHoraire = dfHoraireBrute.melt(
    id_vars=['jour', 'type_veh', 'id_dira', 'voie', 'id_instru_site'],
    value_vars=[c for c in dfHoraireBrute.columns if c[0] == 'h'],
    value_name='valeur', var_name='heure').rename(columns={'type_veh': 'indicateur', 'voie': 'voie_init'})
dfHoraire['date_heure'] = dfHoraire.apply(lambda x: pd.to_datetime(f"{x.jour.date()} {x.heure.split('_')[0].replace('h','').rjust(2, '0')}:00:00"), axis=1)
dfHoraire['sens'] = dfHoraire.voie_init.apply(lambda x: ' '.join(x.split(' ')[:2]).lower())
dfHoraire['voie'] = dfHoraire.voie_init.apply(lambda x: ' '.join(x.split(' ')[2:]).lower() if len(x.split(' ')) > 2 else 'section courante')
dfHoraire['periode_agreg'] = '1 h'
dfHoraireFinal = dfHoraire.drop([c for c in dfHoraire.columns if c not in attributMesureTrafic], axis=1)


# transfert en bdd
with ct.ConnexionBdd(bdd) as c:
    dfHoraireFinal.to_sql('trafic', c.sqlAlchemyConn, schema='mesures_physiques', if_exists='append', index=False)


# lecture des données individuelles tout sens confondus
fichierVersBordeauxSemaine1 = r'C:\Users\martin.schoreisz\Box\Cerema\3E-Prod_Env_Risq\E6-Nuisances\E61-Acoustique\60-Etudes_Locales\2022-BruitRessentiBdxMet\4-Travaux_en_cours\mesures\trafic\exD936\du_04-04-2022 au 18-04-2022_CEPV\CSV\Semaine1\Vers_Bordeaux\00030093-20220331123748.CSV'
fichierVersBordeauxSemaine2 = r'C:\Users\martin.schoreisz\Box\Cerema\3E-Prod_Env_Risq\E6-Nuisances\E61-Acoustique\60-Etudes_Locales\2022-BruitRessentiBdxMet\4-Travaux_en_cours\mesures\trafic\exD936\du_04-04-2022 au 18-04-2022_CEPV\CSV\Semaine2\Vers_Bordeaux\00030095-20220407104915.CSV'
fichierVersRocadeSemaine1 = r'C:\Users\martin.schoreisz\Box\Cerema\3E-Prod_Env_Risq\E6-Nuisances\E61-Acoustique\60-Etudes_Locales\2022-BruitRessentiBdxMet\4-Travaux_en_cours\mesures\trafic\exD936\du_04-04-2022 au 18-04-2022_CEPV\CSV\Semaine1\Vers_Rocade\00000033-20220331122920.CSV'
fichierVersRocadeSemaine2 = r'C:\Users\martin.schoreisz\Box\Cerema\3E-Prod_Env_Risq\E6-Nuisances\E61-Acoustique\60-Etudes_Locales\2022-BruitRessentiBdxMet\4-Travaux_en_cours\mesures\trafic\exD936\du_04-04-2022 au 18-04-2022_CEPV\CSV\Semaine2\Vers_Rocade\00000119-20220407104120.csv'
dfBm = pd.concat([pd.read_csv(e, names=['date', 'heure', 'vitesse', 'longueur', 'div', 'voie', 'reverse'], skiprows=5).assign(sens=k) 
 for k, v in {'vers bordeaux': [fichierVersBordeauxSemaine1, fichierVersBordeauxSemaine2],
              'vers libourne': [fichierVersRocadeSemaine1, fichierVersRocadeSemaine2]}.items() 
 for e in v])
dfBm['date_heure'] = pd.to_datetime(dfBm.date + ' ' + dfBm.heure, dayfirst=True)
dfBm['indicateur'] = dfBm.longueur.apply(lambda x: 'VL' if x <= 6 else 'PL')


# regroupement en 6 minutes pour coller aux données DIR
dfBm6min = dfBm.groupby([pd.Grouper(freq='6min', key='date_heure'), 'indicateur', 'sens']).agg({'date': 'count', 'vitesse': lambda x: harmonic_mean(list(x))}).reset_index().rename(
    columns={'date': 'valeur'}).sort_values(['sens', 'date_heure', 'indicateur'])


# formatage pour insertion dans Bdd
df6minFormatBdd = pd.concat([dfBm6min.loc[dfBm6min.indicateur.isin(('VL', 'PL'))][['date_heure', 'indicateur', 'valeur', 'sens']],
                             dfBm6min.drop('valeur', axis=1).loc[dfBm6min.indicateur == 'VL'].rename(
                                 columns={'vitesse': 'Vmoy_VL'}).melt(
                                 id_vars=['date_heure', 'sens'], value_vars='Vmoy_VL', value_name='valeur', var_name='indicateur'),
                             dfBm6min.drop('valeur', axis=1).loc[dfBm6min.indicateur == 'PL'].rename(
                                 columns={'vitesse': 'Vmoy_PL'}).melt(
                                 id_vars=['date_heure', 'sens'], value_vars='Vmoy_PL', value_name='valeur', var_name='indicateur')]
                           ).assign(id_instru_site=6,
                                    periode_agreg='6 min',
                                    voie='section courante')


# transfert en bdd
with ct.ConnexionBdd(bdd) as c:
    df6minFormatBdd.to_sql('trafic', c.sqlAlchemyConn, schema='mesures_physiques', if_exists='append', index=False)


# estimation
# lecture du fichier creer
dfEstim = pd.read_json(r'C:\Users\martin.schoreisz\Box\Cerema\3E-Prod_Env_Risq\E6-Nuisances\E61-Acoustique\60-Etudes_Locales\2022-BruitRessentiBdxMet\4-Travaux_en_cours\mesures\trafic\exD936\estimation_Q_V\estimationDebitsVitesse.json')


# création d'un index de temps par 30 minutes avec champs de jointure vers le fichier d'estim
dfEstimTot = pd.DataFrame(pd.date_range('2022-03-21', '2022-03-31 12:30:00', freq='30min'), columns=['date_heure'])
dfEstimTot['temp'] = dfEstimTot.date_heure.dt.strftime('%H:%M:%S')
# jointure avec le fichier d'estim
dfEstimNan = (dfEstimTot.loc[dfEstimTot.date_heure.dt.dayofweek.isin(range(5))
              ]
 .merge(dfEstim.loc[dfEstim.type_jour == 'ouvre'], on='temp', how='left')
 .set_index('date_heure')
 .resample('6min').asfreq())


pd.concat([dfEstimNan[i].apply(lambda x: x/5).ffill().reset_index().assign(indicateur=i.upper()).rename(columns={i: 'valeur'}) 
           for i in ('vl', 'pl')])


dfEstimNan[['vts_pl', 'vts_vl']].ffill().rename(columns={'vts_pl': 'Vmoy_PL', 'vts_vl': 'Vmoy_VL'}).stack().reset_index().rename(indicateur)



